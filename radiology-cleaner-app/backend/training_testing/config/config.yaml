# ====================================================================================
# UNIFIED SCORING & PREPROCESSING CONFIGURATION (V3.2 - ROBUST PROMPTING)
# ====================================================================================
# This file centralizes all business logic, weights, rules, and abbreviations for the
# radiology exam standardization engine. It is the "brain" of the application.
#
# HOW TO USE:
# - Adjust weights to change the importance of different matching components.
# - Add new abbreviations to the 'preprocessing' section to handle new exam names.
# - Define new rules and constraints to enforce clinical safety and logic.
# - Comments explain the purpose and impact of each section.
# ====================================================================================

scoring:
  # ----------------------------------------------------------------------------------
  # RETRIEVER & CORE SCORING WEIGHTS
  # Controls the behavior of the main matching algorithm.
  # ----------------------------------------------------------------------------------

  # Number of initial candidates to retrieve from the fast vector search (FAISS).
  # A larger number might find a better match but increases processing time for the scoring stage.
  retriever_top_k: 15

  # --- COMPONENT WEIGHTS ---
  # These weights determine the importance of each structured part of the exam name when
  # calculating the 'component_score'. The total should ideally be 1.0.
  weights_component:
    anatomy: 0.25      # Importance of matching anatomy (e.g., 'head', 'chest').
    modality: 0.35     # Importance of matching modality (e.g., 'CT', 'MRI'). Highest weight as it's critical.
    laterality: 0.10   # Importance of matching laterality (e.g., 'left', 'right').
    contrast: 0.20     # Increased importance of matching contrast status (e.g., 'with contrast').
    technique: 0.10    # Importance of matching specific techniques (e.g., 'MRCP', 'SPECT').

  # --- FINAL SCORE WEIGHTS ---
  # V3 Architecture: These weights combine the 'component_score' (rules-based), 'reranker_score' (cross-encoder),
  # and 'complexity_score' (appropriateness matching) to produce the final confidence score.
  weights_final:
    component: 0.65    # How much to trust the structured component match (rules-based). Increased to counteract reranker dominance.
    reranker: 0.35     # How much to trust the MedCPT cross-encoder reranking score. Reduced to give component scoring more influence.
    # complexity: 0.15   # How much to trust complexity appropriateness (simple inputs prefer simple FSNs).
    # frequency: 0.10  # This appears to be a planned or deprecated feature for popularity-based scoring.
    
    # Reranker-specific weights (optimal tuning per model type)
    reranker_specific:
      # NLP Models - Need more component scoring help due to limited clinical reasoning
      medcpt:
        component: 0.65   
        reranker: 0.35
      biolord:
        component: 0.60   # Slightly more trust in BioLORD than MedCPT
        reranker: 0.40
      default:  # BioLORD fallback
        component: 0.60
        reranker: 0.40

      # OpenRouter Models - Trust their advanced medical reasoning more
      gpt-4o-mini:
        component: 0.45   # Let GPTs medical logic shine
        reranker: 0.55
      claude-3-haiku:
        component: 0.50   # Balanced approach for Claude
        reranker: 0.50
      gemini-2.5-flash-lite:
        component: 0.48   # Slightly favor Geminis reasoning
        reranker: 0.52

  # ----------------------------------------------------------------------------------
  # BONUSES & PENALTIES
  # Fine-tunes the final score based on specific contextual clues and match quality.
  # ----------------------------------------------------------------------------------

  interventional_bonus: 0.15        # Small bonus if both input and candidate are interventional.
  interventional_penalty: -0.20     # Penalty if input is interventional but the candidate is not.
  exact_match_bonus: 0.25           # Bonus if the cleaned input string is an exact match to the candidate name.
  synonym_match_bonus: 0.15         # Bonus if a match is found via an abbreviation (e.g., input 'LSP' matches 'lumbar spine').
  context_match_bonus: 0.10         # General bonus for matching clinical contexts (e.g., both are 'emergency').
  modality_similarity_threshold: 0.8 # A threshold that is likely used elsewhere to gate partial modality credit.

  # --- ANATOMICAL SPECIFICITY SCORING ---
  # A more nuanced approach than a simple penalty. It rewards useful detail and penalizes noise.
  anatomical_specificity_bonus: 0.10    # Bonus for clinically relevant extra words in the candidate (e.g., 'artery').
  general_specificity_penalty: 0.20     # Penalty for irrelevant extra words (e.g., 'procedure', 'examination').
  technique_specificity_bonus: 0.05     # Small bonus for extra words indicating a more specific technique.

  # --- CONTRAST SCORING ---
  # Contrast is clinically critical, so mismatches are penalized heavily.
  contrast_mismatch_score: 0.05     # SEVERE penalty if input is 'with' and candidate is 'without' (or vice-versa).
  contrast_null_score: 0.7          # Score when one has contrast info and the other does not (an ambiguous case).
  prefer_no_contrast_when_unspecified: true  # If true, an input without contrast info will prefer a non-contrast candidate.
  no_contrast_preference_bonus: 0.25         # The bonus applied if the above condition is met.

  # ----------------------------------------------------------------------------------
  # ADVANCED SCORING RULES & CLINICAL SAFETY CONSTRAINTS
  # These sections act as powerful safety nets to prevent clinically dangerous or
  # illogical matches, even if the semantic similarity is high.
  # ----------------------------------------------------------------------------------

  # --- MINIMUM COMPONENT SCORE THRESHOLDS ---
  # CRITICAL: Prevents high semantic similarity from overriding clear component mismatches.
  minimum_component_thresholds:
    enable: true
    # Individual component scores (0.0 to 1.0) must meet these minimums to be considered.
    anatomy_min: 0.1
    modality_min: 0.35  # Lowered from 0.6 to allow more candidates through for component scoring
    laterality_min: 0.0
    contrast_min: 0.3
    technique_min: 0.0
    # The overall weighted component score must also meet a minimum threshold.
    combined_min: 0.25
    # Limits how much a high semantic score can compensate for a poor component score.
    max_semantic_weight: 0.6

  # --- AGE/GENDER CONTEXT BONUSES ---
  gender_context_match_bonus: 0.20  # For matching 'female'/'male' contexts (e.g., prostate, breast).
  age_context_match_bonus: 0.15     # For matching 'paediatric' context.
  pregnancy_context_bonus: 0.25     # Extra strong bonus for matching 'pregnancy' context.

  # --- BIOPSY MODALITY PREFERENCE ---
  # When an input says "Biopsy" without a modality, this prefers the most common modality for that anatomy.
  biopsy_modality_preference: true
  biopsy_organ_modality_preferences:
    lung: { ct: 0.60, us: 0.25, fluoroscopy: -0.50 }
    pulmonary: { ct: 0.60, us: 0.25, fluoroscopy: -0.50 }
    chest: { ct: 0.60, us: 0.20, fluoroscopy: -0.45 }
    thoracic: { ct: 0.60, us: 0.20, fluoroscopy: -0.45 }
    liver: { ct: 0.30, us: 0.35, fluoroscopy: -0.25 }
    hepatic: { ct: 0.40, us: 0.35, fluoroscopy: -0.25 }
    kidney: { ct: 0.30, us: 0.60, fluoroscopy: -0.20 }
    renal: { ct: 0.30, us: 0.60, fluoroscopy: -0.20 }
    thyroid: { us: 0.45, ct: 0.15, fluoroscopy: -0.30 }
    breast: { us: 0.40, mri: 0.25, ct: 0.10, fluoroscopy: -0.40 }
    bone: { ct: 0.30, fluoroscopy: 0.10, us: -0.10 }
    spine: { ct: 0.35, fluoroscopy: 0.05, us: -0.15 }
    vertebr: { ct: 0.35, fluoroscopy: 0.05, us: -0.15 } # For vertebra/vertebral
    prostate: { us: 0.40, mri: 0.30, ct: 0.10, fluoroscopy: -0.25 }
  biopsy_default_preferences:
    ct: 0.25
    us: 0.20
    fluoroscopy: -0.15

  # --- ANATOMY SPECIFICITY PREFERENCE ---
  # For a generic input (e.g., "CT"), this gives a bonus to a generic candidate (e.g., "CT without contrast").
  anatomy_specificity_preference: true
  generic_anatomy_preference_bonus: 0.15

  # --- VESSEL TYPE PREFERENCE ---
  # CRITICAL: When input says "angiography" (generic), prefer arterial over venous studies
  # This ensures clinical accuracy as angiography typically refers to arterial imaging
  vessel_type_preference:
    enable: true
    arterial_preference_bonus: 0.20   # Bonus for arterial studies when input is generic "angiography"
    venous_penalty: -0.15             # Penalty for venous studies when input says "angiography" 
    generic_angiography_indicators:   # Terms that indicate generic angiography (should prefer arteries)
      - "angiography"
      - "angiogram" 
      - "angio"
      - "cta"
      - "ct angiography"
      - "ct angiogram"
      - "mr angiography"
      - "mr angiogram"
      - "mra"
    specific_venous_indicators:        # Terms that specifically indicate venous intent
      - "venography"
      - "venogram"
      - "vein"
      - "venous"
      - "ctv"
      - "ct venography"
      - "mr venography"
      - "mrv"

  # --- ANATOMICAL COMPATIBILITY CONSTRAINTS ---
  # CRITICAL: Blocks anatomically impossible mappings to ensure patient safety.
  anatomical_compatibility_constraints:
    enable: true
    blocking_penalty: -10.0 # A score so low it effectively rejects the match.
    incompatible_pairs:
      - ["breast", "penis"]
      - ["arm", "leg"]
      - ["upper limb", "lower limb"]
      - ["heart", "kidney"]
      - ["lung", "liver"]
      - ["prostate", "breast"]
      - ["prostate", "uterus"]
      - ["artery", "bone"]

  # --- HYBRID MODALITY CONSTRAINTS ---
  # CRITICAL: Prevents incorrect mapping between different types of hybrid scans (e.g., PET/CT vs. PET/MRI).
  hybrid_modality_constraints:
    enable: true
    blocking_penalty: -6.0
    hybrid_incompatibilities:
      - input_pattern: "pet.*ct|pet/ct|pet-ct"
        nhs_exclusions: ["pet.*mri", "pet/mri", "pet-mri", "mri.*pet"]
        reason: "PET/CT should not map to PET/MRI procedures"
      - input_pattern: "pet.*mri|pet/mri|pet-mri"
        nhs_exclusions: ["pet.*ct", "pet/ct", "pet-ct", "ct.*pet"]
        reason: "PET/MRI should not map to PET/CT procedures"
      - input_pattern: "ct.*mri|ct/mri"
        nhs_exclusions: ["mri.*ct", "mri/ct"]
        reason: "Mixed CT/MRI modalities should have consistent ordering"

  # --- DIAGNOSTIC PROTECTION RULES ---
  # CRITICAL: Prevents a simple diagnostic exam (e.g., "XR Chest") from mapping to an interventional one.
  diagnostic_protection:
    enable: true
    blocking_penalty: -8.0
    diagnostic_indicators:
      - "standard"
      - "routine"
      - "screening"
      - "plain"
      - "simple"
      - "without guidance"
      - "non-contrast"
    interventional_indicators:
      - "biopsy"
      - "guided"
      - "guidance"
      - "drainage"
      - "injection"
      - "insertion"
      - "stent"
      - "ablation"
      - "percutaneous"
      - "picc"

  # --- TECHNIQUE SPECIALIZATION CONSTRAINTS ---
  # DEPRECATED: This functionality is now handled by the complexity scoring system (V3.1+)
  # The complexity scoring provides more nuanced matching between input and FSN complexity
  # rather than using hard-coded rules. Disabled to avoid conflicts with complexity scoring.
  technique_specialization_constraints:
    enable: false  # DISABLED: Replaced by complexity scoring system
    blocking_penalty: -10.0
    specialization_rules:
      "diffusion tensor": { required_indicators: ["diffusion", "dti", "tensor"] }
      "fmri": { required_indicators: ["functional", "fmri", "bold"] }
      "perfusion": { required_indicators: ["perfusion", "pwi", "asl"] }
      "spectroscopy": { required_indicators: ["spectroscopy", "mrs"] }
      "ct colonography": { required_indicators: ["colonography", "virtual colonoscopy"] }
      "ct angiography": { required_indicators: ["angiography", "angio", "cta"] }
      "hrct": { required_indicators: ["high resolution", "hrct"] }
      "with contrast": { required_indicators: ["with contrast", "c+", "iv"] }
      "spect": { required_indicators: ["spect", "single photon"] }

  # --- WORD LISTS FOR SPECIFICITY SCORING ---
  anatomical_detail_words:
    - "artery"
    - "vein"
    - "vessel"
    - "aorta"
    - "carotid"
    - "coronary"
    - "pulmonary"
    - "renal"
    - "lobe"
    - "segment"
    - "vertebra"
    - "disc"
  administrative_detail_words:
    - "procedure"
    - "examination"
    - "study"
    - "scan"
    - "imaging"
    - "view"
    - "projection"
  
  # --- CLINICAL SPECIFICITY SCORING ---
  # Rewards NHS entries that match the clinical specificity level of the input
  clinical_specificity_scoring:
    enable: true
    specificity_match_bonus: 0.15      # Bonus when clinical specificity levels match
    generic_over_specific_penalty: -0.10  # Penalty when NHS is generic but input is specific
    
    # Clinical specificity patterns (specific → generic hierarchy)
    clinical_specificity_patterns:
      # Pregnancy/Obstetric specificity
      pregnancy_specific:
        - "first trimester"
        - "second trimester" 
        - "third trimester"
        - "1st trimester"
        - "2nd trimester"
        - "3rd trimester"
      pregnancy_generic:
        - "pregnancy"
        - "obstetric"
        - "multiple pregnancy"
        - "prenatal"
        
      # Anatomical specificity (can be extended for other cases)
      anatomical_specific:
        - "lumbar spine"
        - "cervical spine"
        - "thoracic spine"
      anatomical_generic:
        - "spine"

# ====================================================================================
# MODALITY SIMILARITY
# Defines a "partial credit" score for related but different modalities.
# ====================================================================================
modality_similarity:
  CT: { CECT: 0.9, DECT: 0.8, HRCT: 0.9, PET: 0.7, XR: 0.2, Fluoroscopy: 0.1 }
  MR: { MRI: 1.0, MRA: 0.95, FMRI: 0.8, CT: 0.1 }
  XR: { "X-ray": 1.0, Xray: 1.0, MG: 0.5, FL: 0.6, DEXA: 0.9 }
  US: { Ultrasound: 1.0, USS: 0.9, MRI: 0.1 }
  MG: { Mammography: 1.0, Mammogram: 1.0, Tomosynthesis: 0.9, XR: 0.5 }
  NM: { "Nuclear Medicine": 1.0, Scintigraphy: 0.8, SPECT: 0.9, PET: 0.4 }
  PET: { "PET/CT": 0.95, CT: 0.7 }
  DEXA: { DXA: 1.0, "Bone Densitometry": 1.0, XR: 0.2 }
  DXA: { DEXA: 1.0, "Bone Densitometry": 1.0, XR: 0.2 }
  IR: { Fluoroscopy: 0.6, CT: 0.2, US: 0.2 }
  FL: { Fluoroscopy: 1.0, XR: 0.6, IR: 0.6 } # Assuming FL is Fluoroscopy

# ====================================================================================
# CONTEXT-AWARE SCORING (DEPRECATED IN FAVOR OF BONUSES ABOVE, KEPT FOR REFERENCE)
# This section appears to be an older model for context scoring. The `context_match_bonus`
# and specific `gender/age/pregnancy_context_bonus` are the modern replacements.
# ====================================================================================
context_scoring:
  emergency_keywords: ["emergency", "urgent", "stat", "trauma", "acute"]
  emergency_bonus: 0.15
  screening_keywords: ["screening", "surveillance", "routine", "annual"]
  screening_bonus: 0.15
  intervention_keywords: ["biopsy", "drainage", "injection", "aspiration", "guided", "picc", "line"]
  intervention_bonus: 0.20
  pregnancy_keywords: ["obstetric", "pregnancy", "prenatal", "fetal", "trimester"]
  pregnancy_bonus: 0.25
  paediatric_keywords: ["paediatric", "pediatric", "paed", "peds", "child", "infant", "newborn"]
  paediatric_bonus: 0.20

# ====================================================================================
# PREPROCESSING CONFIGURATION
# The single source of truth for all text cleaning, normalization, and abbreviation expansion.
# This section is critical for standardizing messy real-world data.
# ====================================================================================
preprocessing:
  # The primary dictionary for expanding medical abbreviations.
  # The key is the abbreviation, and the value is the full term.
  
  medical_abbreviations:
    "II": "image intensifier fluoroscopy"    
    "RF": "radiofrequency fluoroscopy"     
    "USS": "ultrasound scan"               
    "Videofluoroscopy": "videofluoroscopy swallow"  
    "C spine": "cervical spine"            
    "L spine": "lumbar spine"              
    "T spine": "thoracic spine"            
    "Bone density": "dexa"
    "Bone density scan": "dexa"
    "Renogram": "renogram"                
    "Xray": "x-ray"                        

    # --- CRITICAL: CONTRAST ---
    "C+": "with contrast"
    "C-": "without contrast"
    "+C": "with contrast"
    "-C": "without contrast"
    "W/C": "with contrast"
    "W/O C": "without contrast"
    "WC": "with contrast"
    "WOC": "without contrast"
    "WITH C": "with contrast"
    "WITHOUT C": "without contrast"
    "NON CONTRAST": "without contrast"
    "NON-CONTRAST": "without contrast"
    "NO CONTRAST": "without contrast"
    "IV CONTRAST": "with contrast"
    "ORAL CONTRAST": "with contrast"
    "GAD": "with contrast"
    "GADOLINIUM": "with contrast"
    "PRIMOVIST": "with contrast"
    
    # --- AGE/GENDER CONTEXT ---
    "PAED": "paediatric"
    "PEDS": "paediatric"
    "CDH": "congenital hip dysplasia paediatric"
    "INFANT": "infant paediatric"
    "PREGNANCY": "pregnancy"
    "OBSTETRIC": "obstetric pregnancy"
    "PRENATAL": "prenatal pregnancy"
    "TRIMESTER": "trimester pregnancy"
    "MAMMOGRAM": "mammogram female"
    "MAMMOGRAPHY": "mammography female"
    "BREAST": "breast female"
    "PROSTATE": "prostate male"
    "SCROTAL": "scrotal male"
    "SCROTUM": "scrotum male"
    "TESTES": "testes male"
    
    # --- ANATOMICAL ABBREVIATIONS (FROM CODES & COMMON USAGE) ---
    "CHED": "head"
    "CCHT": "chest"
    "CAAP": "abdomen and pelvis"
    "CCAP": "chest abdomen and pelvis"
    "CPAN": "pulmonary angiogram"
    "CKUB": "kidneys ureters bladder"
    "CCSP": "cervical spine"
    "MLSP": "lumbar spine"
    "MCSP": "cervical spine"
    "MPRO": "prostate"
    "MHED": "head"
    "UABD": "abdomen"
    "UPEL": "pelvis"
    "UREN": "renal tract"
    "UCDO": "carotid doppler"
    "ULDV": "venous dvt lower limb"
    "USST": "scrotum and testes"
    "UTHY": "thyroid"
    "UPRT": "pregnancy third trimester"
    "ABD": "abdomen"
    "PELV": "pelvis"
    "LSP": "lumbar spine"
    "CSP": "cervical spine"
    "THY": "thyroid"
    "REN": "renal"
    
    # --- MODALITY & TECHNIQUE ---
    "MRCP": "magnetic resonance cholangiopancreatography"
    "DEXA": "dual-energy x-ray absorptiometry"
    "DXA": "dexa" # Normalize DXA to DEXA
    "NM": "nuclear medicine"
    "IR": "interventional radiology"
    "FL": "fluoroscopy"
    "Mamm": "mammography"
    "PET": "positron emission tomography"
    
    # --- CLINICAL CONTEXT & TRACERS ---
    "DVT": "deep vein thrombosis"
    "V/Q": "ventilation perfusion"
    "MAG3": "mercaptoacetyltriglycine"
    "FDG": "fluorodeoxyglucose"

    # --- NUCLEAR MEDICINE TRACERS ---
    "18F-FDG": "18f fluorodeoxyglucose"
    "F-18 FDG": "18f fluorodeoxyglucose"
    "18F FDG": "18f fluorodeoxyglucose"
    "PSMA": "prostate specific membrane antigen"
    "18F-PSMA": "18f prostate specific membrane antigen"
    "F-18 PSMA": "18f prostate specific membrane antigen"
    "18F PSMA": "18f prostate specific membrane antigen"
    "DCFPYL": "18f dcfpyl"
    "18F-DCFPYL": "18f dcfpyl"
    "PYL": "18f dcfpyl"
    "GA-68": "gallium 68"
    "GA68": "gallium 68"
    "68GA": "gallium 68"
    "DOTATATE": "gallium 68 dotatate"
    "DOTANOC": "gallium 68 dotanoc"
    "DOTATOC": "gallium 68 dotatoc"
    "SPECT": "single photon emission computed tomography"
    "WBSP": "whole body spect"
    
    # --- PROCEDURE & BREAST IMAGING ---
    "WB": "whole body"
    "PICC": "peripherally inserted central catheter"
    "XA": "x-ray angiography"
    "BR": "breast"
    "BBMA": "bilateral mammogram"
    "BRMA": "mammogram"
    "BTBB": "bilateral breast tomosynthesis"
    "BRUS": "breast ultrasound"
    
    # --- LATERALITY & DIRECTIONAL ---
    "BILAT": "bilateral"
    "BIL": "bilateral"
    "BOTH": "bilateral"
    "RT": "right"
    "LT": "left"
    "R": "right"
    "L": "left"
    "AP": "anteroposterior"
    "PA": "posteroanterior"
    "LAT": "lateral"
    
    # --- COMMON STUDY ABBREVIATIONS ---
    "ABDPELV": "abdomen and pelvis"
    "CAP": "chest abdomen pelvis"
    "KUB": "kidneys ureters bladder"
    "3RD": "third"
    
  # Normalizes different ways of writing the same anatomy to a single standard form.
  # This is applied after medical abbreviations.
  anatomy_synonyms:
    # --- AUGMENTED LIST FOR BETTER NORMALIZATION ---
    "ABDOMEN": "abdomen"
    "ABDO": "abdomen"
    "TUMMY": "abdomen"
    "BRAIN": "brain"
    "CRANIUM": "head"
    "CHED": "head"
    "THORAX": "chest"
    "CCHT": "chest"
    "LUNGS": "chest"
    "PELV": "pelvis"
    "KIDNEYS": "kidney"
    "RENAL": "kidney"
    "CCSP": "cervical spine"
    "MLSP": "lumbar spine"
    "LSPINE": "lumbar spine"
    "CSPINE": "cervical spine"
    "TSPINE": "thoracic spine"
    "MAMMARY": "breast"
    
  anatomy_vocabulary:
    head: head
    brain: brain
    skull: head
    cranium: head
    sinus: sinuses
    sinuses: sinuses
    orbit: orbit
    orbits: orbit
    face: face
    neck: neck
    chest: chest
    thorax: chest
    lung: chest
    lungs: chest
    heart: heart
    cardiac: heart
    mediastinum: mediastinum
    pulmonary: chest
    abdomen: abdomen
    abdo: abdomen
    tummy: abdomen
    pelvis: pelvis
    pelvic: pelvis
    liver: liver
    kidney: kidney
    kidneys: kidney
    renal: kidney
    pancreas: pancreas
    spleen: spleen
    bladder: bladder
    ureter: ureters
    ureters: ureters
    uterus: uterus
    ovary: ovary
    ovaries: ovary
    prostate: prostate
    spine: spine
    spinal: spine
    'cervical spine': 'cervical spine'
    'thoracic spine': 'thoracic spine'
    'lumbar spine': 'lumbar spine'
    sacrum: sacrum
    coccyx: coccyx
    shoulder: shoulder
    shoulders: shoulder
    arm: arm
    arms: arm
    elbow: elbow
    elbows: elbow
    wrist: wrist
    wrists: wrist
    hand: hand
    hands: hand
    finger: finger
    fingers: finger
    thumb: thumb
    thumbs: thumb
    hip: hip
    hips: hip
    thigh: thigh
    thighs: thigh
    knee: knee
    knees: knee
    leg: leg
    legs: leg
    ankle: ankle
    ankles: ankle
    foot: foot
    feet: foot
    toe: toe
    toes: toe
    breast: breast
    breasts: breast
    mammary: breast
    mammogram: breast
    mammography: breast
    thyroid: thyroid
    bone: bone
    bones: bone
    joint: joint
    joints: joint
    'soft tissue': 'soft tissue'
    muscle: muscle
    muscles: muscle
    adrenal: adrenal
    adrenals: adrenal
    biliary: biliary
    gallbladder: gallbladder
    'lymph node': 'lymph node'
    'lymph nodes': 'lymph node'
    parotid: parotid
    submandibular: submandibular
    'salivary gland': 'salivary gland'
    'salivary glands': 'salivary gland'
    'aortic arch': 'aortic arch'
    carotid: carotid
    'carotid arteries': carotid
    eye: eye
    eyes: eye
    ear: ear
    ears: ear
    scrotum: scrotum
    testes: testes
    testis: testes
    'whole body': 'whole body'

# ====================================================================================
# SECONDARY PIPELINE CONFIGURATION (V2 - MORE ROBUST)
# ====================================================================================
secondary_pipeline:
  # System prompt to set the model's role and behavior firmly.
  system_prompt: |
    You are a silent, efficient JSON API endpoint. Your sole purpose is to receive a query and return a single, valid JSON object with no extra text, commentary, or markdown. Do not say "Here is the JSON object". Do not use markdown. Respond ONLY with the JSON.

  # User prompt with clearer instructions and placeholders.
  prompt_template: |
    You are a meticulous radiology data standardization expert. Your task is to map an `input_exam` to the most appropriate candidate from a given list, following a strict principle of parsimony.

    **GUIDING PRINCIPLE: The Principle of Parsimony**
    The correct match is the one that includes all specified components from the `input_exam` (modality, anatomy, contrast, etc.) while introducing the **absolute minimum** of new, unspecified information. Do not "upgrade" the exam to a more complex version.

    **INPUT EXAM:**
    `{exam_name}`

    **CANDIDATE PROCEDURES:**
    Each candidate has a short `primary_name` and a detailed `snomed_fsn` (Fully Specified Name). **You must evaluate both.** The FSN often contains critical details about technique or context that are essential for an accurate match.
    ```json
    {similar_exams}
    ```

    **INSTRUCTIONS:**
    1.  **Decompose Input:** Identify the essential components of the `input_exam`: Modality, Anatomy, Contrast, and any other key specifiers.
    2.  **Evaluate Candidates:** For each candidate, compare the `input_exam` against both its `primary_name` and its `snomed_fsn`. The FSN is the ultimate source of truth for the procedure's definition. 
        ### ### NEW INSTRUCTION HERE ### ###
        **NOTE: You can safely ignore the text `(procedure)` at the end of the FSN, as it is present on all entries and not clinically relevant for differentiation.**
    3.  **Apply Parsimony Filter:**
        -   A candidate is only a good match if the details in its `snomed_fsn` are justified by the `input_exam`.
        -   For example, if the input is "CT Chest", a candidate with FSN "CT of chest with contrast (procedure)" is a poor match because it adds "contrast".
    4.  **Select Best Match:** Choose the candidate whose `snomed_fsn` best represents the procedure described in the `input_exam` without adding unsubstantiated details.

    **CRITICAL INSTRUCTION FOR NO MATCH:**
    If no candidate's `snomed_fsn` is a suitable match (e.g., critical modality mismatch), you MUST return `null` for `best_match_snomed_id` and `best_match_procedure_name`, and `0.0` for `confidence`.

    **EXAMPLE OF CORRECT LOGIC:**
    - If `input_exam` is "US Breast", and all candidates have a `snomed_fsn` indicating "Mammography...", you MUST return a "no match" response.

    **RETURN A SINGLE, VALID JSON OBJECT AND NOTHING ELSE.**

    ```json
    {{
        "best_match_snomed_id": "The SNOMED ID of the chosen procedure, or null",
        "best_match_procedure_name": "The primary_name of the chosen procedure, or null",
        "confidence": <Float between 0.0 and 1.0>,
        "reasoning": "My choice is the most parsimonious match based on the FSN. I rejected [Other Candidate FSN] because it added [New Information] not present in the input."
    }}
    ```

  # Model configuration
  models:
    - "anthropic/claude-3.5-sonnet"
    - "openai/gpt-4-turbo"
    - "google/gemini-2.5-pro"
  
  # API settings
  temperature: 0.0 # Set to 0 for maximum determinism and adherence to instructions
  max_tokens: 600
  
  # Pipeline settings
  confidence_threshold: 0.8
  max_concurrent_requests: 5
